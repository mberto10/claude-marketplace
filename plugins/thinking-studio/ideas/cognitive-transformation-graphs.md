---
idea: Cognitive Transformation Graphs
sources: ["my AI strategy framework", "knowledge work analysis"]
connects_to: ["mid-chain-commoditization", "skills-as-modules", "value-at-boundaries"]
categories: ["foundational-lens", "systems-thinking", "ai-strategy"]
---

# Cognitive Transformation Graphs

## My Understanding

Knowledge work isn't "tasks" - it's **transformations**. Any repeatable mental operation that turns one representation into another. Parse a document. Classify an input. Summarize findings. Each is a transform with inputs and outputs.

The insight that changed how I see things: knowledge work is a **directed graph** of these transforms chained together. Not a linear process, not a checklist - a graph with nodes (transforms) and edges (dependencies).

This reframing matters because it makes the structure of work *visible* and *decomposable*. Once you see work as a graph, you can ask: which nodes can be automated? Which edges can be parallelized? Where are the bottlenecks?

## Why This Resonates

I was trying to understand what AI actually changes about work. "AI automates tasks" felt too crude. Some tasks are easy to automate, some aren't - but why?

The graph framing clicked because it revealed that AI doesn't automate "tasks" - it automates **specific types of transforms**. Perception transforms (transcribe, parse). Abstraction transforms (classify, cluster). Synthesis transforms (summarize, translate).

This gave me a vocabulary for precision: instead of "AI helps with writing," I can say "AI handles synthesis transforms but struggles with decision transforms."

## Examples That Stuck

**The six-layer stack:**

| Layer | Transform primitives | AI analogues |
|-------|---------------------|--------------|
| Perception | detect, transcribe, parse | vision models, OCR |
| Abstraction | cluster, classify, tag | embeddings, vector search |
| Reasoning | chain-of-thought, hypothesis | LLMs with tool-use |
| Synthesis | summarize, translate, reframe | style-transfer, summarization |
| Decision | rank, choose, prioritize | RL-tuned models |
| Communication | explain, persuade, package | chat generation |

This table lives in my head now. When I look at any knowledge workflow, I mentally map it to these layers.

**A journalism workflow as graph:**
```
[raw event]
    → [perception: gather sources]
    → [abstraction: identify key claims]
    → [reasoning: verify, connect dots]
    → [synthesis: draft narrative]
    → [decision: what angle, what to cut]
    → [communication: package for audience]
```

Each arrow is a transform. Each node has different AI substitutability.

## How I Use It

I reach for this when:
- Analyzing any knowledge workflow for AI potential
- Explaining to others why some work automates easily and some doesn't
- Designing human-AI collaboration (which transforms go where?)
- Strategic planning about AI impact on roles/industries

My trigger question: "What are the transforms in this workflow, and which layers do they live in?"

## My Explanatory Moves

When I explain this to someone, I start with:

"Think of any mental operation as a transform - input in, output out. Transcribing audio is a transform. Summarizing a document is a transform. Now chain them together into a graph - that's what knowledge work actually is."

Then I show the six-layer table and ask them to map their own work onto it.

The "aha" usually comes when they realize: "Oh, AI is really good at layers 1-4 but humans still own 5-6" - and that's when the strategic implications land.

## Tensions & Edges

**The layers aren't clean.** Real work bleeds across layers. A "synthesis" task might require "decision" judgment. The stack is a useful simplification, not ground truth.

**Graphs can be redrawn.** The same work can be decomposed multiple ways. The "right" graph depends on what you're optimizing for.

**Not all transforms are equal.** Some transforms in a graph are load-bearing (screw them up, everything fails). Others are peripheral. The framework doesn't inherently capture criticality.

## Source Passages

> "Cognitive Transformation: Think of it as any repeatable mental operation that turns one representation into another."

> "Knowledge-work tasks look like directed graphs of such transforms."
