---
idea: Human-AI Interface Design
sources: ["AI strategy framework", "organizational design thinking"]
connects_to: ["membrane-model", "value-at-boundaries", "skills-as-modules", "provenance-architecture"]
categories: ["meta-skill", "organizational-design", "ai-strategy"]
---

# Human-AI Interface Design

## My Understanding

The companies that win won't have better AI - they'll have better **interfaces between human judgment and AI execution**. This is a nascent discipline combining:

- Information architecture (how do you structure context for AI?)
- Interaction design (how do humans and AI collaborate?)
- Organizational design (how do teams integrate AI workflow?)
- Editorial philosophy (what do humans own vs. delegate?)
- Trust architecture (how do audiences perceive AI-mediated content?)

This is the *meta-skill* - the skill of designing how humans and AI work together. Everything else (skills, processes, tools) flows from getting this right.

## Why This Resonates

I kept seeing companies adopt AI and get mediocre results - not because the AI was bad, but because the human-AI interface was poorly designed. Humans were either over-involved (bottlenecking everything) or under-involved (quality disasters).

The interface framing clicked because it puts the focus on the *collaboration pattern*, not just the AI capability. A brilliant AI with a bad interface produces worse outcomes than a decent AI with a great interface.

It also gave me a framework for what "AI implementation" actually means: it's interface design, not tool deployment.

## Examples That Stuck

**The five-layer framework:**

1. **Task Decomposition Interface** - Breaking work into human vs. AI components
2. **Context-Passing Interface** - What information flows between human and AI
3. **Quality Control Interface** - How humans validate AI output at scale
4. **Feedback & Improvement Interface** - How the system learns
5. **Trust & Transparency Interface** - How audiences understand AI's role

Each layer needs explicit design. Most companies only think about layer 1 (if that).

**Progressive Context Architecture:**
```
Level 0: Universal Context (always loaded)
  - Brand voice, legal boundaries, core audience
Level 1: Domain Context (loaded when relevant)
  - Subject expertise, historical coverage
Level 2: Task Context (specific to this request)
  - Assignment requirements, constraints
Level 3: Real-time Context (dynamic during collaboration)
  - Human feedback, new information
```

This is information architecture for AI consumption - a new discipline.

**Risk-Based Quality Stratification:**
- Tier 1: Automated checks (100% of content)
- Tier 2: Spot checks (10% sample)
- Tier 3: High-risk full review (flagged items)
- Tier 4: Reputation-critical (always human-led)

You can't review 10x more output just because AI produces 10x more. You need stratified QC.

## How I Use It

I reach for this when:
- Designing any AI-augmented workflow
- Diagnosing why an AI implementation isn't working
- Training teams on AI collaboration
- Thinking about competitive differentiation

My trigger questions:
- "What's the human-AI boundary in this workflow?"
- "Is the interface explicit or implicit?"
- "Which of the five layers is weakest?"

## My Explanatory Moves

I usually start with the paradox:

"Most AI implementations fail not because the AI is bad, but because no one designed the interface. It's like having a brilliant new hire but never defining their role, their inputs, their outputs, their relationship to the team."

Then I introduce the layers:

"There are five things you have to design: How you split tasks. What context you pass. How you catch errors. How the system learns. How you communicate AI's role to others."

"Most companies only think about the first one, maybe the second. Then they wonder why it's not working."

## Tensions & Edges

**Interface design is invisible.** It's hard to point to, hard to measure. Organizations tend to focus on visible things (tools, outputs) rather than the interface that produces them.

**Interfaces ossify.** Once you've designed an interface, it's hard to change. Early design decisions lock in. This argues for more experimentation before committing.

**No established best practices.** This is genuinely new. There's no textbook, no proven playbook. We're all figuring it out.

**Interface design is organizational change.** You're not just designing a tool workflow - you're changing how people work. That triggers all the usual change management challenges.

**The meta-skill is hard to teach.** You can teach someone to use an AI tool. Teaching them to *design* the human-AI interface is a different challenge.

## Source Passages

> "The companies that win won't have better AIâ€”they'll have better interfaces between human judgment and AI execution."

> "This is a nascent discipline that combines: Information architecture, Interaction design, Organizational design, Editorial philosophy, Trust architecture."

> "A well-designed human-AI interface should be nearly invisible to both the human operator and the audience."

> "When your interface is excellent, people stop asking 'Is this AI or human?' and start asking 'Is this valuable?'"
